{
    "experiment_types": [
        "ablation studies",
        "hyperparameter tuning",
        "cross-modal retrieval task",
        "downstream task training and evaluation",
        "modality fusion analysis",
        "finetuning strategies",
        "pre-training and augmentation comparison",
        "token aggregation and projection",
        "attention analysis",
        "retrieval-augmented VQA",
        "effectiveness of knowledge augmentation",
        "text-based/feature-based vision comparison",
        "effects of late interaction and ROIs",
        "object-centric ROI ablation",
        "graph-based visual representation learning",
        "retrieval system configuration",
        "model configuration",
        "training configuration",
        "multi-modal NER and RE performance comparison",
        "label-wise F1 score analysis",
        "knowledge quality impact analysis",
        "approximation effect analysis",
        "module speed comparison",
        "case study",
        "online experimental settings",
        "convergence analysis",
        "parameters sensitivity analysis",
        "zero-shot sketch-based image retrieval (ZS-SBIR)",
        "visual delta generation (VDG) evaluation",
        "semi-supervised CIR setup"
    ],
    "baselines": [
        "VisualBERT (Li et al., 2019b)",
        "ViLBERT (Lu et al., 2019)",
        "Movie+MCAN (Nguyen et al., 2020)",
        "[Gabeur et al., 2020]",
        "[Patrick et al., 2020]",
        "CLIP (Radford et al., 2021)",
        "BM25 (Robertson and Zaragoza, 2009)",
        "DPR (Karpukhin et al., 2020)",
        "VRR-IMG (Luo et al., 2021) using LXMERT",
        "VRR-CAP (Luo et al., 2021)",
        "TriG (Gao et al., 2022)",
        "AVLnet (Lee et al., 2020)",
        "MCN (Zhou et al., 2018)",
        "FrozenInTime (Miech et al., 2021)",
        "CLIP4CLIP (Li et al., 2020)",
        "CrossTask (Caba Heilbron et al., 2019)",
        "HT100M (Sun et al., 2019)",
        "MIL-NCE (Miech et al., 2020)",
        "UniVL (Luo et al., 2020)",
        "ActBERT (Lu et al., 2020)",
        "ConceptBERT [Garderes et al., 2020]",
        "KRISP [Marino et al., 2021]",
        "VRR [Luo et al., 2021]",
        "MAVEx [Wu et al., 2022]",
        "KAT-T5 [Gui et al., 2021]",
        "TRiG-Ensemble [Gao et al., 2022]",
        "RA-VQA",
        "PICa [Yang et al., 2022]",
        "KAT [Gui et al., 2021]",
        "Prophet [Shao et al., 2023]",
        "PromptCap [Hu et al., 2022a]",
        "REVIVE [Lin et al., 2022]",
        "PALI [Chen et al., 2022b]",
        "Flamingo [Alayrac et al., 2022]",
        "PaLM-E [Driess et al., 2023]",
        "BERT-DPR",
        "NQ-DPR",
        "NQ-ANCE",
        "T5-ANCE (Yu et al., 2023)",
        "Anchor-DR (Xie et al., 2023)",
        "VinVL-DPR",
        "CLIP-DPR",
        "UniVL-DR (Liu et al., 2023b)",
        "CTRL [8]",
        "MCN [1]",
        "ROLE [22]",
        "ACRN [21]",
        "READ [11]",
        "MAN [38]",
        "CMIN [42]",
        "ORG [43]",
        "STVC [27]",
        "ITA (Wang et al., 2022b)",
        "baseline model without any retrieval module and MoE module",
        "FOMH (Lu et al. 2019a)",
        "OMH-DQ (Lu et al. 2019b)",
        "SAPMH (Zheng et al. 2020)",
        "CAAE (Yelamarthi et al. 2018)",
        "CVAE (Yelamarthi et al. 2018)",
        "SEMPCYC (Dutta and Akata 2019)",
        "SAKE (Liu et al. 2019)",
        "IIAE (Hwang et al. 2020)",
        "LCALE (Lin et al. 2020)",
        "OCEAN (Zhu et al. 2020)",
        "DSN (Wang et al. 2021)",
        "Combiner [2]",
        "BLIP [29]",
        "BLIP_tdm",
        "Pic2Word",
        "SEARLE",
        "CoVR",
        "CASE",
        "InstructBLIPâ€™s pretrained weights with ViT-G/14 and Q-Former based on Vicuna-13B",
        "LLaMA2-13B",
        "LoRA parameters for instruction tuning"
    ],
    "benchmarks": [
        "Flickr-30K",
        "COCO",
        "Conceptual Captions",
        "HowTo100M [Miech et al., 2019]",
        "MSR-VTT [Xu et al., 2016]",
        "ActivityNet Captions [Caba Heilbron et al., 2015]",
        "LSMDC [Torabi et al., 2016]",
        "OKVQA",
        "ReMuQ",
        "GS-112K",
        "Wikipedia 21M",
        "YouCook2 [Zhugan et al., 2018]",
        "CrossTask [Caba Heilbron et al., 2019]",
        "Mining YouTube [Alayrac et al., 2017]",
        "Google Search Corpus for OK-VQA [Luo et al., 2021]",
        "Wikipedia Corpus for OK-VQA",
        "WIT dataset [Srinivasan et al., 2021]",
        "FVQA [Wang et al., 2017]",
        "Infoseek [Chen et al., 2023b]",
        "WebQA (Chang et al., 2022)",
        "ClueWeb22-MM",
        "ClueWeb22 (Overwijk et al., 2022)",
        "Charades-STA [8]",
        "TACoS [30]",
        "Twitter-15",
        "Twitter-17",
        "SNAP",
        "WikiDiverse",
        "MNRE",
        "MIRFlickr (Huiskes and Lew 2008)",
        "NUS-WIDE (Chua et al. 2009)",
        "Sketchy (Sangkloy et al. 2016)",
        "TU-Berlin (Eitz et al. 2010)",
        "QuickDraw (Dey et al. 2019)",
        "CIRR [36]",
        "FashionIQ [52]",
        "NLVR2 [45]",
        "DeepFashion [34]"
    ],
    "metrics": [
        "Recall-at-1/5/10",
        "VQA test-dev and test-std splits",
        "Performance with different amounts of retrieved captions during training and inference",
        "Unplugged performance",
        "Fine-tuning after pre-training",
        "mean rank (MnR)",
        "median rank (MdR)",
        "recall at rank N (R@N)",
        "GPU hours/epochs speed",
        "inference speed for text and video bi-directional retrieval",
        "Precision @ K (P@K)",
        "Recall @ K (R@K)",
        "MRR",
        "P@1",
        "P@5",
        "average recall over all tasks",
        "standard recall metrics R@1, R@5, R@10",
        "median rank (MedR)",
        "VQA Score",
        "Exact Match (EM)",
        "Pseudo Relevance Recall (PRRecall@K)",
        "MRR @10",
        "R(n,m)",
        "IoU",
        "F1 score",
        "label-wise F1 score",
        "entity-label-based F1 score",
        "marginal probability distribution approximation effect",
        "speed of each module on Tesla V100 GPU",
        "Mean Average Precision (MAP)",
        "cosine distance",
        "hamming distance",
        "mAP",
        "mAP@200",
        "mAP@all",
        "Prec@100",
        "Prec@200",
        "R@1",
        "R@5",
        "R@10",
        "R_sGK",
        "recall scores at top K retrieval results (R@K)",
        "results under collected subset (R_sGK)"
    ]
}